{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1100af0e-0390-4773-8e9b-00e9fbca9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223140457388908\n"
     ]
    }
   ],
   "source": [
    "# reading\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1Uaa3K9Nh1LmKacFHnieBILj2LI6bjcfM/view?usp=share_link\"\n",
    "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    "housing = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = housing.drop(columns=\"SalePrice\")\n",
    "y = housing[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=8)\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "pipe = make_pipeline(\n",
    "        SimpleImputer(strategy='median'),\n",
    "        StandardScaler(),\n",
    "        KNeighborsRegressor())\n",
    "\n",
    "# parameter grid for pipeline\n",
    "pipe_params = {\n",
    "    'simpleimputer__strategy':['median', 'mean'],\n",
    "    'standardscaler__with_mean':[True, False],\n",
    "    'kneighborsregressor__n_neighbors': list(range(1, 20)),\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "    'kneighborsregressor__p': [1, 2],\n",
    "    'kneighborsregressor__algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "trained_pipe = GridSearchCV(pipe,\n",
    "                            pipe_params,\n",
    "                            cv = 5)\n",
    "trained_pipe.fit(X_train, y_train)\n",
    "\n",
    "# test accuracy on the test set\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = trained_pipe.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30519833-440e-4445-a986-43043457a885",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.13-py2.py3-none-any.whl (33 kB)\n",
      "Collecting yarg\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/valeriiasatsiuk/anaconda3/lib/python3.10/site-packages (from yarg->pipreqs) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/valeriiasatsiuk/anaconda3/lib/python3.10/site-packages (from requests->yarg->pipreqs) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/valeriiasatsiuk/anaconda3/lib/python3.10/site-packages (from requests->yarg->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/valeriiasatsiuk/anaconda3/lib/python3.10/site-packages (from requests->yarg->pipreqs) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/valeriiasatsiuk/anaconda3/lib/python3.10/site-packages (from requests->yarg->pipreqs) (1.26.14)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=e92ff5c0dbce205bf0ef10dabb650e64ce80a2d85e550ef0d0614be92711e183\n",
      "  Stored in directory: /Users/valeriiasatsiuk/Library/Caches/pip/wheels/7c/d7/8d/2156234738063e3d4a39ba77dc677046100e62766b53807189\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, yarg, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.13 yarg-0.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab3a4a42-b9d4-4cf4-a81a-d0b6bbc73c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pipreqs Downloads/Regression/trained_pipe_knn.sav\n",
    "#Downloads/Regression/trained_pipe_knn.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f1fdfe-8934-4bc8-92aa-0bfd9800cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2b9b932-c157-45d3-ae3d-bff5b4a64d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80213f59-07f4-4e0f-9747-5407363000be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the trained pipeline\n",
    "import pickle\n",
    "pickle.dump(trained_pipe,\n",
    "            open(file='NEW1_pipe_knn.sav',\n",
    "                 mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "532937bd-d3cf-4a1a-a3c6-b0ea36f9e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "model = pickle.load(open('NEW1_pipe_knn.sav', 'rb'))\n",
    "\n",
    "import pandas as pd\n",
    "new_house = pd.DataFrame({\n",
    "    'LotArea':[9000],\n",
    "    'TotalBsmtSF':[1000],\n",
    "    'BedroomAbvGr':[5],\n",
    "    'GarageCars':[4]\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_house)\n",
    "\n",
    "#st.write(\"The price of the house is:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee144a9-f64a-4380-8116-8f1d4a02aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Housing Prices Prediction\")\n",
    "\n",
    "st.write(\"\"\"\n",
    "### Project description\n",
    "We have trained several models to predict the price of a house based on features such as the area of the house and the condition and quality of their different rooms.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "model = pickle.load(open('NEW1_pipe_knn.sav', 'rb'))\n",
    "\n",
    "LotArea = st.number_input(\"Lot Area\")\n",
    "TotalBsmtSF = st.number_input(\"Basement Square Feet\")\n",
    "BedroomAbvGr = st.number_input(\"Number of Bedrooms\")\n",
    "GarageCars = st.number_input(\"Car spaces in Garage\")\n",
    "\n",
    "import pandas as pd\n",
    "new_house = pd.DataFrame({\n",
    "    'LotArea':[LotArea],\n",
    "    'TotalBsmtSF':[TotalBsmtSF],\n",
    "    'BedroomAbvGr':[BedroomAbvGr],\n",
    "    'GarageCars':[GarageCars]\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_house)\n",
    "\n",
    "st.write(\"The price of the house is:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
